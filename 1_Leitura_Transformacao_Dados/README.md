# Teste 1: TransformaÃ§Ã£o de Dados ANS (ETL)

Este projeto implementa um pipeline de **ETL (Extract, Transform, Load)** automatizado para coletar, processar e consolidar dados de Despesas das Operadoras de Planos de SaÃºde, conforme disponibilizado no portal de Dados Abertos da ANS.

## ğŸ“‹ Funcionalidades

O script executa as seguintes tarefas de forma autÃ´noma:
1.  **Scraping DinÃ¢mico:** Baixa os arquivos de demonstraÃ§Ãµes contÃ¡beis dos Ãºltimos trimestres.
2.  **Crawler de Enriquecimento (CADOP):** Acessa o diretÃ³rio FTP da ANS, identifica a versÃ£o mais recente do arquivo `Relatorio_Cadop` (independente de mudanÃ§as de nomeclatura) e o utiliza para enriquecer os dados.
3.  **Tratamento de Encoding:** Detecta e corrige automaticamente problemas de codificaÃ§Ã£o (`UTF-8`, `Latin-1`, `CP1252`) para evitar caracteres corrompidos (*mojibake*).
4.  **AnÃ¡lise de Qualidade:** Gera um log detalhado de inconsistÃªncias (valores negativos, zerados ou datas invÃ¡lidas).
5.  **ConsolidaÃ§Ã£o:** Gera um arquivo final `.zip` contendo o CSV padronizado.

---

## ğŸš€ Como Executar

### PrÃ©-requisitos
* Python 3.8 ou superior.
* ConexÃ£o com a internet (para baixar os dados da ANS).

### Passo a Passo

1.  **Instale as dependÃªncias:**
    Navegue atÃ© a pasta do projeto e execute:
    ```bash
    pip install -r requirements.txt
    ```

2.  **Execute o Pipeline:**
    Utilize o script principal que orquestra todo o processo:
    ```bash
    python main.py
    ```

3.  **Resultado:**
    Ao final da execuÃ§Ã£o, dois arquivos serÃ£o gerados na raiz:
    * ğŸ“¦ `consolidado_despesas.zip`: O arquivo CSV final com os dados processados.
    * ğŸ“„ `relatorio_inconsistencias.txt`: Log contendo os alertas sobre a qualidade dos dados.

---

## ğŸ› ï¸ DecisÃµes TÃ©cnicas e Arquitetura

### 1. Enriquecimento de Dados (Data Enrichment)
Os arquivos originais de despesas utilizam apenas o cÃ³digo `REG_ANS` para identificar as operadoras. Para atender ao requisito de exibir **CNPJ** e **RazÃ£o Social**:
* Implementei um mÃ³dulo que baixa a tabela auxiliar **CADOP** (Cadastro de Operadoras).
* O script cruza os dados (`Join`) usando o `REG_ANS` como chave primÃ¡ria.
* **ResiliÃªncia:** Caso a chave nÃ£o bata exatamente (ex: zeros Ã  esquerda), o algoritmo tenta normalizar a chave (`zfill`) para garantir o *match*.

### 2. Crawler de ResiliÃªncia (CADOP)
A ANS altera frequentemente o nome do arquivo de cadastro (ex: de `Relatorio_Cadop.csv` para `Relatorio_Cadop_Ativas.csv` ou `.zip`).
* **SoluÃ§Ã£o:** Em vez de *hardcodar* a URL, criei um *crawler* que varre o diretÃ³rio FTP, identifica o arquivo vÃ¡lido mais recente e obtÃ©m o link dinamicamente. Isso evita que o pipeline quebre com atualizaÃ§Ãµes simples do portal.

### 3. Tratamento de Caracteres (Encoding)
Arquivos governamentais frequentemente misturam encodings (`UTF-8` e `Latin-1`).
* **SoluÃ§Ã£o:** Implementei uma leitura com tratamento de exceÃ§Ã£o em cascata. O sistema tenta ler em `UTF-8`; se falhar, tenta `Latin-1` e `CP1252`.
* **SaÃ­da:** O arquivo final Ã© salvo forÃ§ando `utf-8-sig` (com BOM), garantindo que acentos abram corretamente no **Excel** e editores de texto.

### 4. AnÃ¡lise de InconsistÃªncias
Conforme solicitado, o sistema audita os dados e loga os seguintes cenÃ¡rios no arquivo `relatorio_inconsistencias.txt`:
* **Valores Negativos:** Alerta contÃ¡bil.
* **Valores Zerados:** Alerta de qualidade de dado.
* **InconsistÃªncia de Datas:** Trimestres nÃ£o identificados.
* **Duplicidade de Cadastro:** Verifica se um mesmo CNPJ aparece associado a RazÃµes Sociais diferentes ao longo dos arquivos.

---

## ğŸ“‚ Estrutura do Projeto

```text
1_Leitura_Transformacao_Dados/
â”‚
â”œâ”€â”€ main.py                  # Ponto de entrada (Orquestrador)
â”œâ”€â”€ requirements.txt         # Lista de bibliotecas necessÃ¡rias
â”œâ”€â”€ README.md                # DocumentaÃ§Ã£o do projeto
â”œâ”€â”€ consolidado_despesas.zip # (Gerado apÃ³s execuÃ§Ã£o) Arquivo final
â”œâ”€â”€ relatorio_inconsistencias.txt # (Gerado apÃ³s execuÃ§Ã£o) Logs de qualidade
â”‚
â””â”€â”€ src/                     # CÃ³digo Fonte
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ scraper.py           # MÃ³dulo de download (Web Scraping)
    â””â”€â”€ processor.py         # MÃ³dulo de ETL e Regras de NegÃ³cio
---

ğŸ‘¤ Autor
Ãtallo de Santana GuimarÃ£es
